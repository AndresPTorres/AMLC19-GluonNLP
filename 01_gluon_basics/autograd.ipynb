{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automatic Differentiation with `autograd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Models are trained to get better and better as a function of experience. Usually, getting better means minimizing a loss function. To achieve this goal, the model iteratively computes the gradient of the loss with respect to weights and then updates the internal weights accordingly. While the gradient calculations are straightforward through a chain rule, for complex models, working it out by hand can be tedious.\n",
    "\n",
    "Before diving deep into the model training, you must understand how MXNetâ€™s `autograd` package expedites this work by automatically calculating derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic usage\n",
    "\n",
    "Firstly, import the `autograd` package and analyze the case study for a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:36:29.255811Z",
     "start_time": "2019-06-13T16:36:28.119160Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Case study: autograd for $f(x) = 2 x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Start by assigning an initial value of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:36:29.262414Z",
     "start_time": "2019-06-13T16:36:29.258567Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = nd.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In MXNet, an `NDArray` for which a gradient needs to be calculated and stored can be invoked using its `attach_grad` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Attach gradient storage\n",
    "\n",
    "Calculating gradients requires extra computation, and a variable in which to store it. Utilize the `.attach_grad()` function to store the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:36:29.267429Z",
     "start_time": "2019-06-13T16:36:29.264217Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Define and record y = f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, define the function $y=f(x)$. To let MXNet store $y$, so that gradients can be computed later, put the definition inside the `autograd.record()` scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:36:29.274746Z",
     "start_time": "2019-06-13T16:36:29.269163Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 2.  8.]\n",
      " [18. 32.]]\n",
      "<NDArray 2x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    y = 2 * x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Invoke back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Invoke back propagation (backprop) by calling `y.backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:36:29.280657Z",
     "start_time": "2019-06-13T16:36:29.277604Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Verify Computed Gradients\n",
    "\n",
    "Next, verify the computed gradients; note that $y=2x^2$ and $\\frac{dy}{dx} = 4x$, which should be\n",
    "\n",
    "`[[4, 8],[12, 16]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 4.  8.]\n",
       " [12. 16.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
